So, how should we think about cost?  And the way computer scientists think about cost is quite different from how  most people think about cost.  So, if you're normally thinking about cost.  You've got a specific object.  Let's say you've got a cool car.  Supposed to be a cool car.  Doesn't quite look like a cool car.  And it's got a cost associated with it.  Let's say, that's a $25,000 car.  And you have some other car.  So you have one car.  It's got a particular cost.  That's what it costs you to get that car.  You could have another car that would be smaller and green and  let's say that car cost $10,000.  And when we think about the cost of things normally,  we have very specific things.  And they specific costs.  And we know that the red car costs $25,000.  The green car costs $10,000.  The red car costs more than the green car.  We just need to compare those costs.  So when we think about the cost of algorithms,  we don't have a specific execution in mind usually.  What we want to understand is how the cost depends on the input.  So we might have two different algorithms.  Let's say this is algorithm one, and  we have a second algorithm that solves the same problem, and  both of these are algorithms that take inputs, and produce output.  And, if we want to decide which algorithm is better,  we don't have a specific cost for the algorithm the way we do for the cars.  And, we can say the red car costs more than the green car.  The cost depends on the actual input that we run the algorithm on.  So, it might be the case for some inputs, algorithm one is faster.  And, for other inputs, Algorithm two is faster, and  I should label this algorithm two.  So what we need to understand is how the cost of executing the algorithm  depends on the input.  We don't want to do that for every specific input.  If we had to do that for every input,  well we might as well just run it on the input and see what it costs.  What we want to do is be able to predict this.  Without actually having to run it on every input.  Normally, there isn't that much that matters about this specific input.  The main thing that's going to matter about the input  is the size of the input.  That's not always going to be the case, and  we'll see examples where other properties of input matter.  But the primary way that we talk about cost in computer science is  based on the size of the input.  As the size of the input increases,  how does the cost evaluate the procedure increase?  So cost, ultimately always comes down to money and when it comes down to money,  well what are the things that cost money when we execute algorithms?  And the main things that cost money are the time it takes to finish,  if we get an answer more quickly, we've spent less time on it.  And we can also rent computers by the time to execute.  There are lots of cloud computing services now that will give you  a processor of a certain power for a certain amount of time for  a certain number of cents per hour.  So time really is money, and so we don't need to turn our cost estimates into  money, because we don't necessarily know how much our computing cost will be.  But if we can understand the time it takes to execute that will give us  a good sense of the cost.  The other main cost is often memory.  So, if we know that we need a certain amount of memory  to be able to execute our algorithm.  That tells us something about the size of computer we need and  how expensive that's going to be.  So we don't usually talk about cost in terms of dollars  when we analyze algorithms.  We're talking about cost in terms of time and memory.  But those things in real implementations end up being cost in terms of dollars.  So we're mostly going to focus on measuring time and  time is usually the most important cost of running an algorithm.  Memory is often another consideration.  